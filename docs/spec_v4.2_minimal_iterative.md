# QC-GN2oMS2-EI „Ç∑„Çπ„ÉÜ„É†Ë©≥Á¥∞ÊäÄË°ì‰ªïÊßòÊõ∏ v4.2
## PyTorchÁµ±‰∏ÄÁí∞Â¢É„ÉªÊúÄÂ∞èÊßãÊàê„Ç¢„Éó„É≠„Éº„ÉÅÔºàÂèçÂæ©ÊîπÂñÑÊà¶Áï•Ôºâ

**‰ΩúÊàêÊó•**: 2025-12-02
**ÂØæË±°„Ç∑„Çπ„ÉÜ„É†**: NExtIMS (NIST EI-MS Prediction System)
**Âü∫Áõ§„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£**: QC-GN2oMS2 (PNNL)
**„Éè„Éº„Éâ„Ç¶„Çß„Ç¢**: NVIDIA GeForce RTX 5070 Ti (Blackwell sm_120)
**Ë®≠Ë®àÊñπÈáù**: **Start Simple, Iterate Based on Evidence**

---

## üìã ÁõÆÊ¨°

1. [‰∏ªË¶ÅÂ§âÊõ¥ÁÇπÔºàv4.1 ‚Üí v4.2Ôºâ](#‰∏ªË¶ÅÂ§âÊõ¥ÁÇπv41--v42)
2. [Ë®≠Ë®àÂì≤Â≠¶ÔºöÊúÄÂ∞èÊßãÊàê„Ç¢„Éó„É≠„Éº„ÉÅ](#Ë®≠Ë®àÂì≤Â≠¶ÊúÄÂ∞èÊßãÊàê„Ç¢„Éó„É≠„Éº„ÉÅ)
3. [„Ç∑„Çπ„ÉÜ„É†Ê¶ÇË¶Å](#„Ç∑„Çπ„ÉÜ„É†Ê¶ÇË¶Å)
4. [„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Ë®≠Ë®à](#„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Ë®≠Ë®à)
5. [Phase 0: BDE-db2Áí∞Â¢ÉÊßãÁØâ](#phase-0-bde-db2Áí∞Â¢ÉÊßãÁØâ)
6. [Phase 1: „Éá„Éº„ÇøÊ∫ñÂÇô](#phase-1-„Éá„Éº„ÇøÊ∫ñÂÇô)
7. [Phase 2: GNNÂ≠¶Áøí](#phase-2-gnnÂ≠¶Áøí)
8. [Phase 3: Ë©ï‰æ°„Å®ÂèçÂæ©ÊîπÂñÑÂà§Êñ≠](#phase-3-Ë©ï‰æ°„Å®ÂèçÂæ©ÊîπÂñÑÂà§Êñ≠)
9. [Phase 4: ÁâπÂæ¥ÈáèÊã°ÂºµÔºàÊù°‰ª∂‰ªò„ÅçÔºâ](#phase-4-ÁâπÂæ¥ÈáèÊã°ÂºµÊù°‰ª∂‰ªò„Åç)
10. [Phase 5: Êé®Ë´ñ„Éó„É≠„Çª„ÇπÔºà„É¢„Éá„É´ÈÅãÁî®Ôºâ](#phase-5-Êé®Ë´ñ„Éó„É≠„Çª„Çπ„É¢„Éá„É´ÈÅãÁî®)
11. [Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ë©≥Á¥∞](#Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ë©≥Á¥∞)
12. [ÈñãÁô∫Áí∞Â¢ÉÊßãÁØâ](#ÈñãÁô∫Áí∞Â¢ÉÊßãÁØâ)
13. [„Çø„Ç§„É†„É©„Ç§„É≥](#„Çø„Ç§„É†„É©„Ç§„É≥)
14. [ÂèÇËÄÉÊñáÁåÆ](#ÂèÇËÄÉÊñáÁåÆ)

---

## ‰∏ªË¶ÅÂ§âÊõ¥ÁÇπÔºàv4.1 ‚Üí v4.2Ôºâ

### ‚úÖ v4.2„Åß„ÅÆÂ§ßÂπÖÁ∞°Á¥†Âåñ

| È†ÖÁõÆ | v4.1 | v4.2 | Â§âÊõ¥ÁêÜÁî± |
|------|------|------|---------|
| **„Éé„Éº„ÉâÁâπÂæ¥Ê¨°ÂÖÉ** | 128 (41+87) | **16 (16+0)** | QC-GN2oMS2ÂÆüË®ºÊ∏à„ÅøË®≠Ë®à„Å´Ê∫ñÊã† |
| **„Ç®„ÉÉ„Ç∏ÁâπÂæ¥Ê¨°ÂÖÉ** | 64 (12+52) | **3 (3+0)** | ÊúÄÂ∞èÈôê„ÅÆÁâπÂæ¥ÈáèÔºàBDE+ÁµêÂêàÊ¨°Êï∞+Áí∞Ôºâ |
| **‰∫àÂÇôÊ¨°ÂÖÉ** | 139 (87+52) | **0** | ÂÆüË®º‰∏ªÁæ©„Ç¢„Éó„É≠„Éº„ÉÅÔºàÂøÖË¶ÅÊÄßË®ºÊòéÂæå„Å´ËøΩÂä†Ôºâ |
| **„É°„É¢„É™‰ΩøÁî®Èáè** | Á¥Ñ1.3GB | **Á¥Ñ0.16GB** | **-88%ÂâäÊ∏õ** |
| **Ë®≠Ë®àÊñπÈáù** | Êã°ÂºµÊÄßÈáçË¶ñ | **„Ç∑„É≥„Éó„É´„ÅïÈáçË¶ñ** | Start simple, iterate |

### üéØ Ë®≠Ë®àÂì≤Â≠¶„ÅÆËª¢Êèõ

**v4.1**: „ÄåÂ∞ÜÊù•„ÅÆÊã°Âºµ„Å´ÂÇô„Åà„Å¶‰∫àÂÇôÊ¨°ÂÖÉ„ÇíÂ§ßÈáè„Å´Á¢∫‰øù„Äç
**v4.2**: „ÄåÊúÄÂ∞èÊßãÊàê„ÅßÂÆüË£Ö ‚Üí ÊÄßËÉΩË©ï‰æ° ‚Üí ÂøÖË¶Å„Å´Âøú„Åò„Å¶ÊÆµÈöéÁöÑ„Å´Êã°Âºµ„Äç

**Ê†πÊã†**:
- QC-GN2oMS2„ÅåMS/MS„Åß16Ê¨°ÂÖÉ„Éé„Éº„ÉâÁâπÂæ¥„ÄÅ2Ê¨°ÂÖÉ„Ç®„ÉÉ„Ç∏ÁâπÂæ¥„Åß**Cosine Similarity 0.88**„ÇíÈÅîÊàê
- ÈÅéÂâ∞Ë®≠Ë®à„ÇíÈÅø„Åë„ÄÅÂÆüË®º„Éá„Éº„Çø„Å´Âü∫„Å•„ÅèÊÑèÊÄùÊ±∫ÂÆö
- È´òÈÄü„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥ÔºàÂ≠¶ÁøíÈÄüÂ∫¶Âêë‰∏äÔºâ„Å´„Çà„Çã„Ç¢„Ç∏„É£„Ç§„É´ÈñãÁô∫

---

## Ë®≠Ë®àÂì≤Â≠¶ÔºöÊúÄÂ∞èÊßãÊàê„Ç¢„Éó„É≠„Éº„ÉÅ

### Âü∫Êú¨ÂéüÂâá

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 1: ÊúÄÂ∞èÊßãÊàê„ÅßÂÆüË£ÖÔºàv4.2Ôºâ                          ‚îÇ
‚îÇ   - „Éé„Éº„Éâ: 16Ê¨°ÂÖÉÔºàQC-GN2oMS2Ê∫ñÊã†Ôºâ                     ‚îÇ
‚îÇ   - „Ç®„ÉÉ„Ç∏: 3Ê¨°ÂÖÉÔºàBDE + ÁµêÂêàÊ¨°Êï∞ + Áí∞Ôºâ                 ‚îÇ
‚îÇ   - ÁõÆÊ®ô: Cosine Similarity > 0.80                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Phase 2: ÊÄßËÉΩË©ï‰æ°    ‚îÇ
         ‚îÇ   - Cosine Sim       ‚îÇ
         ‚îÇ   - Top-K Recall     ‚îÇ
         ‚îÇ   - Ê±éÂåñÊÄßËÉΩ         ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Âà§ÂÆö                           ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ ÂçÅÂàÜ       ‚îÇ ‰∏çÂçÅÂàÜ           ‚îÇ
    ‚îÇ (>0.85)    ‚îÇ (<0.85)          ‚îÇ
    ‚Üì            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ÂÆå‰∫ÜÔºÅ  ‚îÇ  ‚îÇ Phase 3: ÁâπÂæ¥ÈáèÂàÜÊûê  ‚îÇ
‚îÇ v4.2Êé°Áî®‚îÇ  ‚îÇ   - AttentionÂàÜÊûê    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ   - Ablation study   ‚îÇ
             ‚îÇ   - ÈáçË¶ÅÁâπÂæ¥„ÅÆÁâπÂÆö   ‚îÇ
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
             ‚îÇ Phase 4: ÊÆµÈöéÁöÑÊã°Âºµ  ‚îÇ
             ‚îÇ   - v4.3: ËøΩÂä†ÁâπÂæ¥   ‚îÇ
             ‚îÇ   - ÂÜçË©ï‰æ°           ‚îÇ
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### QC-GN2oMS2„ÅÆÊïôË®ì

**ÂΩº„Çâ„ÅÆÊàêÂäü‰∫ã‰æã**:
- MS/MS„Åß16Ê¨°ÂÖÉ„Éé„Éº„Éâ„ÄÅ2Ê¨°ÂÖÉ„Ç®„ÉÉ„Ç∏
- Cosine Similarity 0.88ÈÅîÊàê
- Ë´ñÊñá„ÅßÂÆüË®ºÊ∏à„Åø

**Êàë„ÄÖ„ÅÆ‰ªÆË™¨**:
- EI-MS„ÇÇ„Ç∑„É≥„Éó„É´„Å™ÁâπÂæ¥Èáè„ÅßÂçÅÂàÜ„Å™ÂèØËÉΩÊÄß
- Ë§áÈõë„Åï„ÅØÊÆµÈöéÁöÑ„Å´ËøΩÂä†„Åô„Åπ„Åç
- ÊúÄÂàù„Åã„Çâ128Ê¨°ÂÖÉ„ÅØÈÅéÂâ∞Ë®≠Ë®à„ÅÆÂèØËÉΩÊÄßÂ§ß

---

## „Ç∑„Çπ„ÉÜ„É†Ê¶ÇË¶Å

### ÁõÆÁöÑ

NIST 17 EI-MS„Éá„Éº„Çø„Éô„Éº„ÇπÔºàÁ¥Ñ280,000„Çπ„Éö„ÇØ„Éà„É´„ÄÅ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞ÂæåÔºâ„ÇíÁî®„ÅÑ„Å¶„ÄÅ**ÊúÄÂ∞èÈôê„ÅÆÁâπÂæ¥Èáè„ÅßÈ´òÁ≤æÂ∫¶„Å™**Graph Neural Network„Å´„Çà„ÇãEI-MS„Çπ„Éö„ÇØ„Éà„É´‰∫àÊ∏¨„Ç∑„Çπ„ÉÜ„É†„ÇíÊßãÁØâ„Åô„Çã„ÄÇ

### „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Ê¶ÇË¶ÅÂõ≥

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 0: BDE-db2Áí∞Â¢ÉÊßãÁØâÔºàv4.1„Å®Âêå„ÅòÔºâ                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. BDE-db2„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ (531,244 reactions)                   ‚îÇ
‚îÇ 2. BonDNetÂÜçÂ≠¶Áøí (2-3Êó•, RTX 5070 Ti)                        ‚îÇ
‚îÇ 3. Â≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´Ê§úË®º (MAE < 1.0 kcal/molÁõÆÊ®ô)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 1: „Éá„Éº„ÇøÊ∫ñÂÇôÔºàv4.1„Å®Âêå„ÅòÔºâ                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1.1 NIST 17Ë™≠„ÅøËæº„Åø (300,000 spectra)                       ‚îÇ
‚îÇ 1.2 „Éá„Éº„Çø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞                                     ‚îÇ
‚îÇ     - „Çµ„Éù„Éº„ÉàÂÖÉÁ¥†„ÉÅ„Çß„ÉÉ„ÇØ (C,H,O,N,F,S,P,Cl,Br,I)          ‚îÇ
‚îÇ     - ÂàÜÂ≠êÈáè„Éï„Ç£„É´„Çø (MW <= 1000 Da)                         ‚îÇ
‚îÇ     ‚Üí 280,000 spectra (93.3% retention)                     ‚îÇ
‚îÇ 1.3 BonDNet BDEË®àÁÆó (70 min)                                ‚îÇ
‚îÇ 1.4 PyG GraphÁîüÊàêÔºà16Ê¨°ÂÖÉ„Éé„Éº„Éâ„ÄÅ3Ê¨°ÂÖÉ„Ç®„ÉÉ„Ç∏Ôºâ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 2: GNNÂ≠¶ÁøíÔºàÊúÄÂ∞èÊßãÊàêÔºâ                                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 10-layer GATv2Conv + Residual Connections                   ‚îÇ
‚îÇ „Éé„Éº„Éâ: 16Ê¨°ÂÖÉ„ÄÅ„Ç®„ÉÉ„Ç∏: 3Ê¨°ÂÖÉ                               ‚îÇ
‚îÇ RTX 5070 Ti (16GB GDDR7) √ó Á¥Ñ40ÊôÇÈñìÔºàÈ´òÈÄüÂåñÔºâ                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 3: Ë©ï‰æ°„Å®ÂèçÂæ©ÊîπÂñÑÂà§Êñ≠ÔºàNEW!Ôºâ                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ - Cosine SimilarityË©ï‰æ°                                     ‚îÇ
‚îÇ - Top-K RecallË©ï‰æ°                                          ‚îÇ
‚îÇ - Ê±éÂåñÊÄßËÉΩË©ï‰æ°ÔºàÊú™Áü•ÂåñÂêàÁâ©„ÉÜ„Çπ„ÉàÔºâ                          ‚îÇ
‚îÇ - Attention weightsÂàÜÊûê                                     ‚îÇ
‚îÇ ‚Üí Âà§ÂÆö: ÂçÅÂàÜ or ÁâπÂæ¥ÈáèËøΩÂä†ÂøÖË¶Å                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Ë®≠Ë®à

### BDEË®àÁÆó„Éê„ÉÉ„ÇØ„Ç®„É≥„Éâ: BonDNet (BDE-db2ÂÜçÂ≠¶ÁøíÁâà)

Ôºàv4.1„Å®Âêå„Åò - Â§âÊõ¥„Å™„ÅóÔºâ

---

### GNN„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£: 10-layer GATv2ConvÔºàÊúÄÂ∞èÊßãÊàêÁâàÔºâ

#### „É¢„Éá„É´ÊßãÊàê

```python
import torch
import torch.nn as nn
from torch_geometric.nn import GATv2Conv, global_mean_pool

class QCGN2oEI_Minimal(nn.Module):
    """
    QC-GN2oMS2 Architecture for EI-MS Prediction (Minimal Configuration)

    Key design:
    - Minimal feature dimensions (16 node, 3 edge)
    - Inspired by QC-GN2oMS2's proven approach
    - Iterate based on performance evaluation
    """

    def __init__(
        self,
        node_dim: int = 16,        # Minimal node feature dimension
        edge_dim: int = 3,         # Minimal edge feature dimension
        hidden_dim: int = 256,     # Hidden layer dimension
        num_layers: int = 10,      # GATv2Conv layers
        num_heads: int = 8,        # Attention heads
        output_dim: int = 1000,    # Output spectrum bins (m/z 50-1000)
        dropout: float = 0.1
    ):
        super().__init__()

        # Node embedding (16 ‚Üí 256)
        self.node_encoder = nn.Sequential(
            nn.Linear(node_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        # Edge embedding (3 ‚Üí 256)
        self.edge_encoder = nn.Sequential(
            nn.Linear(edge_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        # 10-layer GATv2Conv with residual connections
        self.gat_layers = nn.ModuleList()
        self.residual_layers = nn.ModuleList()

        for i in range(num_layers):
            # GATv2Conv layer
            self.gat_layers.append(
                GATv2Conv(
                    in_channels=hidden_dim,
                    out_channels=hidden_dim // num_heads,
                    heads=num_heads,
                    edge_dim=hidden_dim,  # Edge features
                    dropout=dropout,
                    concat=True,          # Concatenate heads
                    residual=True         # PyG 2.6.1+ feature
                )
            )

            # Residual connection projection
            self.residual_layers.append(
                nn.Linear(hidden_dim, hidden_dim)
            )

        # Global pooling + prediction head
        self.prediction_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, output_dim),
            nn.Softmax(dim=-1)  # Normalize to intensity distribution
        )

    def forward(self, data):
        """
        Args:
            data: PyG Data object
                - x: Node features [num_nodes, 16]
                - edge_index: Graph connectivity [2, num_edges]
                - edge_attr: Edge features [num_edges, 3]
                - batch: Batch assignment [num_nodes]

        Returns:
            spectrum: Predicted intensity [batch_size, 1000]
        """
        # Encode nodes and edges
        x = self.node_encoder(data.x)
        edge_attr = self.edge_encoder(data.edge_attr)

        # 10-layer GATv2Conv with residual connections
        for gat, residual in zip(self.gat_layers, self.residual_layers):
            x_res = residual(x)  # Residual projection
            x = gat(x, data.edge_index, edge_attr)
            x = x + x_res  # Residual addition
            x = torch.relu(x)

        # Global mean pooling
        x = global_mean_pool(x, data.batch)

        # Predict spectrum
        spectrum = self.prediction_head(x)

        return spectrum
```

#### „Éé„Éº„ÉâÁâπÂæ¥ÈáèÔºà16Ê¨°ÂÖÉÔºâ- QC-GN2oMS2Ê∫ñÊã†

**Ë®≠Ë®àÊñπÈáù**: QC-GN2oMS2„ÅåÂÆüË®º„Åó„ÅüÊúÄÂ∞èÈôê„ÅÆÁâπÂæ¥Èáè„Çª„ÉÉ„Éà

| „Ç´„ÉÜ„Ç¥„É™ | Ê¨°ÂÖÉ | ÂÜÖÂÆπ | ÁêÜÁî± |
|---------|------|------|------|
| **ÂéüÂ≠êÁ®Æ** | 10 | C, H, O, N, F, S, P, Cl, Br, I (one-hot) | ÂÖÉÁ¥†Á®Æ„ÅØÊúÄÈáçË¶ÅÁâπÂæ¥ |
| **Ëä≥È¶ôÊóèÊÄß** | 1 | Binary (aromatic/aliphatic) | „Éï„É©„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥ÂÆâÂÆöÊÄß |
| **Áí∞ÊßãÈÄ†** | 1 | Binary (in ring/not in ring) | ÊßãÈÄ†ÁöÑÂÆâÂÆöÊÄß |
| **„Éè„Ç§„Éñ„É™„ÉÄ„Ç§„Çº„Éº„Ç∑„Éß„É≥** | 3 | SP/SP2/SP3 (one-hot) | ÁµêÂêà„ÅÆÊÄßË≥™ |
| **ÈÉ®ÂàÜÈõªËç∑** | 1 | Gasteiger charge (continuous) | ÈõªÂ≠êÂàÜÂ∏É |
| **ÂêàË®à** | **16** | - | **‰∫àÂÇô„Å™„Åó** |

**ÂâäÈô§„Åï„Çå„ÅüÁâπÂæ¥Ôºàv4.1„Å´„ÅÇ„Å£„Åü„ÇÇ„ÅÆÔºâ**:
- ÂΩ¢ÂºèÈõªËç∑Ôºà3Ê¨°ÂÖÉÔºâ ‚Üí ÈÉ®ÂàÜÈõªËç∑„Åß‰ª£ÊõøÂèØËÉΩ
- Ê∞¥Á¥†ÁµêÂêàÊï∞Ôºà5Ê¨°ÂÖÉÔºâ ‚Üí ÂéüÂ≠êÁ®Æ+„Éè„Ç§„Éñ„É™„ÉÄ„Ç§„Çº„Éº„Ç∑„Éß„É≥„Åã„ÇâÊé®Ê∏¨ÂèØËÉΩ
- Ê¨°Êï∞Ôºà6Ê¨°ÂÖÉÔºâ ‚Üí „Ç∞„É©„ÉïÊßãÈÄ†„Åã„ÇâÂ≠¶ÁøíÂèØËÉΩ
- „É©„Ç∏„Ç´„É´ÈõªÂ≠êÔºà3Ê¨°ÂÖÉÔºâ ‚Üí EI-MS„Åß„ÅØ„ÅÇ„Åæ„ÇäÈáçË¶Å„Åß„Å™„ÅÑÂèØËÉΩÊÄß
- „Ç≠„É©„É™„ÉÜ„Ç£Ôºà3Ê¨°ÂÖÉÔºâ ‚Üí Á´ã‰ΩìÂåñÂ≠¶„ÅØ‰∫åÊ¨°ÁöÑ
- ÂéüÂ≠êÈáè„ÉªvdWÂçäÂæÑ„ÉªÈõªÊ∞óÈô∞ÊÄßÂ∫¶Ôºà3Ê¨°ÂÖÉÔºâ ‚Üí ÂéüÂ≠êÁ®Æ„Å®Áõ∏Èñ¢

**ÂÆüË£Ö‰æã**:
```python
from rdkit import Chem
from rdkit.Chem import AllChem
import numpy as np

SUPPORTED_ELEMENTS = ['C', 'H', 'O', 'N', 'F', 'S', 'P', 'Cl', 'Br', 'I']

def get_atom_features_minimal(atom: Chem.Atom) -> np.ndarray:
    """
    Extract 16-dimensional minimal atom features

    Inspired by QC-GN2oMS2's proven approach
    """

    # 1. Atom type (10-dim one-hot)
    atom_symbol = atom.GetSymbol()
    if atom_symbol not in SUPPORTED_ELEMENTS:
        raise ValueError(f"Unsupported element: {atom_symbol}")
    atom_type = one_hot(atom_symbol, SUPPORTED_ELEMENTS)  # 10 dims

    # 2. Aromatic (1-dim binary)
    aromatic = [int(atom.GetIsAromatic())]  # 1 dim

    # 3. In ring (1-dim binary)
    in_ring = [int(atom.IsInRing())]  # 1 dim

    # 4. Hybridization (3-dim one-hot: SP/SP2/SP3)
    hyb = atom.GetHybridization()
    if hyb == Chem.HybridizationType.SP:
        hybrid = [1, 0, 0]
    elif hyb == Chem.HybridizationType.SP2:
        hybrid = [0, 1, 0]
    elif hyb == Chem.HybridizationType.SP3:
        hybrid = [0, 0, 1]
    else:
        hybrid = [0, 0, 1]  # Default to SP3 for SP3D, etc.
    # 3 dims

    # 5. Partial charge (1-dim continuous)
    if atom.HasProp('_GasteigerCharge'):
        partial_charge = [atom.GetDoubleProp('_GasteigerCharge')]
    else:
        partial_charge = [0.0]
    # 1 dim

    # Concatenate: 10 + 1 + 1 + 3 + 1 = 16 dims
    features = np.concatenate([
        atom_type,      # 10
        aromatic,       # 1
        in_ring,        # 1
        hybrid,         # 3
        partial_charge  # 1
    ])

    assert len(features) == 16, f"Feature length mismatch: {len(features)}"

    return features

def one_hot(value, choices):
    """One-hot encoding"""
    encoding = [0] * len(choices)
    if value in choices:
        encoding[choices.index(value)] = 1
    return encoding
```

#### „Ç®„ÉÉ„Ç∏ÁâπÂæ¥ÈáèÔºà3Ê¨°ÂÖÉÔºâ- ÊúÄÂ∞èÊßãÊàê

**Ë®≠Ë®àÊñπÈáù**: BDE + ÁµêÂêàÊÉÖÂ†±„ÅÆÊúÄÂ∞è„Çª„ÉÉ„Éà

| „Ç´„ÉÜ„Ç¥„É™ | Ê¨°ÂÖÉ | ÂÜÖÂÆπ | ÁêÜÁî± |
|---------|------|------|------|
| **BDEÔºàÊúÄÈáçË¶ÅÔºâ** | 1 | Bond Dissociation Energy from BonDNet (normalized) | „Éï„É©„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥Á¢∫Áéá„ÅÆ‰∏ªË¶ÅÂõ†Â≠ê |
| **ÁµêÂêàÊ¨°Êï∞** | 1 | Bond order (1.0, 2.0, 3.0, 1.5 for aromatic) | ÁµêÂêà„ÅÆÂº∑„Åï |
| **Áí∞ÂÜÖÁµêÂêà** | 1 | Binary (in ring/not in ring) | Áí∞„ÅÆÂÆâÂÆöÊÄß |
| **ÂêàË®à** | **3** | - | **‰∫àÂÇô„Å™„Åó** |

**ÂâäÈô§„Åï„Çå„ÅüÁâπÂæ¥Ôºàv4.1„Å´„ÅÇ„Å£„Åü„ÇÇ„ÅÆÔºâ**:
- ÁµêÂêàÊ¨°Êï∞one-hotÔºà4Ê¨°ÂÖÉÔºâ ‚Üí ÈÄ£Á∂öÂÄ§1Ê¨°ÂÖÉ„Åß‰ª£Êõø
- ÂÖ±ÂΩπÔºà1Ê¨°ÂÖÉÔºâ ‚Üí Ëä≥È¶ôÊóèÊÄß„ÉªÁí∞ÊßãÈÄ†„Åã„ÇâÊé®Ê∏¨ÂèØËÉΩ
- Á´ã‰ΩìÂåñÂ≠¶Ôºà3Ê¨°ÂÖÉÔºâ ‚Üí EI-MS„Åß„ÅØ„ÅÇ„Åæ„ÇäÈáçË¶Å„Åß„Å™„ÅÑ
- ÂõûËª¢ÂèØËÉΩÊÄßÔºà1Ê¨°ÂÖÉÔºâ ‚Üí „Éï„É©„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥„Å∏„ÅÆÂΩ±ÈüøÂ∞è
- ÁµêÂêàË∑ùÈõ¢Ôºà1Ê¨°ÂÖÉÔºâ ‚Üí ÁµêÂêàÊ¨°Êï∞„Å®Áõ∏Èñ¢

**ÂÆüË£Ö‰æã**:
```python
def get_bond_features_minimal(bond: Chem.Bond, bde_value: float) -> np.ndarray:
    """
    Extract 3-dimensional minimal bond features
    """

    # 1. BDE (normalized, 1-dim)
    bde_normalized = normalize_bde(bde_value)  # [0, 1] range

    # 2. Bond order (continuous, 1-dim)
    bond_type = bond.GetBondType()
    if bond_type == Chem.BondType.SINGLE:
        bond_order = 1.0
    elif bond_type == Chem.BondType.DOUBLE:
        bond_order = 2.0
    elif bond_type == Chem.BondType.TRIPLE:
        bond_order = 3.0
    elif bond_type == Chem.BondType.AROMATIC:
        bond_order = 1.5
    else:
        bond_order = 1.0  # Default

    # 3. In ring (binary, 1-dim)
    in_ring = float(bond.IsInRing())

    # Concatenate: 1 + 1 + 1 = 3 dims
    features = np.array([bde_normalized, bond_order, in_ring])

    assert len(features) == 3, f"Feature length mismatch: {len(features)}"

    return features

def normalize_bde(bde_kcal_mol: float) -> float:
    """Normalize BDE to [0, 1] range"""
    return (bde_kcal_mol - 50.0) / 150.0  # 50-200 kcal/mol range
```

---

## Phase 0: BDE-db2Áí∞Â¢ÉÊßãÁØâ

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

---

## Phase 1: „Éá„Éº„ÇøÊ∫ñÂÇô

### 1.1 NIST 17„Éá„Éº„ÇøË™≠„ÅøËæº„Åø

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

### 1.2 „Éá„Éº„Çø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

### 1.3 BDEÂâçË®àÁÆóÔºàBonDNet BDE-db2Ôºâ

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

### 1.4 PyG GraphÁîüÊàêÔºàÊúÄÂ∞èÊßãÊàêÁâàÔºâ

```python
# src/data/graph_generator.py
"""
PyTorch Geometric Graph Generator (Minimal Configuration)
"""

import torch
from torch_geometric.data import Data
from rdkit import Chem
from rdkit.Chem import AllChem
import numpy as np
from typing import Dict, List
import h5py

class GraphGeneratorMinimal:
    """Generate PyTorch Geometric graphs with minimal features (16 node, 3 edge)"""

    def __init__(self, bde_cache_path: str = "data/processed/bde_cache.h5"):
        self.bde_cache = h5py.File(bde_cache_path, 'r')

    def smiles_to_graph(
        self,
        smiles: str,
        spectrum: np.ndarray,
        molecule_idx: int
    ) -> Data:
        """
        Convert SMILES to PyG Data object with minimal features

        Args:
            smiles: SMILES string
            spectrum: Target spectrum [1000]
            molecule_idx: Index for BDE cache lookup

        Returns:
            PyG Data object with 16-dim nodes and 3-dim edges
        """
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return None

        # Add hydrogens for complete graph
        mol = Chem.AddHs(mol)

        # Compute Gasteiger charges (needed for partial charge feature)
        AllChem.ComputeGasteigerCharges(mol)

        # Get BDE values from cache
        bde_dict = {}
        if str(molecule_idx) in self.bde_cache:
            grp = self.bde_cache[str(molecule_idx)]
            for bond_idx in grp.keys():
                bde_dict[int(bond_idx)] = float(grp[bond_idx][()])

        # Node features (16 dims per atom)
        node_features = []
        for atom in mol.GetAtoms():
            node_features.append(get_atom_features_minimal(atom))

        x = torch.tensor(node_features, dtype=torch.float)

        # Edge features (3 dims per bond)
        edge_index = []
        edge_attr = []

        for bond in mol.GetBonds():
            i = bond.GetBeginAtomIdx()
            j = bond.GetEndAtomIdx()
            bond_idx = bond.GetIdx()

            # Get BDE value
            bde_value = bde_dict.get(bond_idx, 100.0)  # Default if not in cache

            # Bidirectional edges
            edge_index.append([i, j])
            edge_index.append([j, i])

            bond_features = get_bond_features_minimal(bond, bde_value)
            edge_attr.append(bond_features)
            edge_attr.append(bond_features)  # Same features for both directions

        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
        edge_attr = torch.tensor(edge_attr, dtype=torch.float)

        # Target spectrum
        y = torch.tensor(spectrum, dtype=torch.float)

        # Create PyG Data
        data = Data(
            x=x,
            edge_index=edge_index,
            edge_attr=edge_attr,
            y=y,
            smiles=smiles
        )

        return data
```

---

## Phase 2: GNNÂ≠¶Áøí

### 2.1 Â≠¶Áøí„Çπ„ÇØ„É™„Éó„ÉàÔºàÊúÄÂ∞èÊßãÊàêÁâàÔºâ

```python
# scripts/train_gnn_minimal.py
"""
Train QC-GN2oEI model (Minimal Configuration)
"""

import torch
import torch.nn as nn
from torch_geometric.loader import DataLoader
from src.models.qcgn2oei_minimal import QCGN2oEI_Minimal
import wandb
import yaml
from pathlib import Path
from tqdm import tqdm

def cosine_similarity_loss(pred, target):
    """Cosine Similarity Loss (same as QC-GN2oMS2)"""
    pred_norm = pred / (pred.norm(dim=1, keepdim=True) + 1e-8)
    target_norm = target / (target.norm(dim=1, keepdim=True) + 1e-8)
    cosine_sim = (pred_norm * target_norm).sum(dim=1)
    return (1 - cosine_sim).mean()

def train_qcgn2oei_minimal(config_path: str = "config/training_minimal.yml"):
    """Train QC-GN2oEI model with minimal features"""

    # Load config
    with open(config_path) as f:
        config = yaml.safe_load(f)

    # Initialize wandb
    wandb.init(project="qcgn2oei-minimal", config=config)

    # Device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # Data loaders
    train_data = torch.load("data/processed/nist17_train.pt")
    val_data = torch.load("data/processed/nist17_val.pt")

    train_loader = DataLoader(
        train_data,
        batch_size=config['training']['batch_size'],
        shuffle=True,
        num_workers=4
    )

    val_loader = DataLoader(
        val_data,
        batch_size=config['training']['batch_size'],
        shuffle=False,
        num_workers=4
    )

    # Model (minimal configuration)
    model = QCGN2oEI_Minimal(
        node_dim=16,      # Minimal
        edge_dim=3,       # Minimal
        hidden_dim=config['model']['hidden_dim'],
        num_layers=config['model']['num_layers'],
        num_heads=config['model']['num_heads'],
        output_dim=config['model']['output_dim'],
        dropout=config['model']['dropout']
    ).to(device)

    print(f"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
    print(f"Node features: 16 dims (minimal)")
    print(f"Edge features: 3 dims (minimal)")

    # Optimizer (RAdam from QC-GN2oMS2)
    optimizer = torch.optim.RAdam(
        model.parameters(),
        lr=config['training']['learning_rate'],
        weight_decay=config['training']['weight_decay']
    )

    # Learning rate scheduler
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config['training']['num_epochs'],
        eta_min=1e-6
    )

    # Training loop
    best_val_loss = float('inf')

    for epoch in range(config['training']['num_epochs']):
        # Train
        model.train()
        train_loss = 0.0

        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1} [Train]"):
            batch = batch.to(device)

            optimizer.zero_grad()
            pred = model(batch)
            loss = cosine_similarity_loss(pred, batch.y)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        train_loss /= len(train_loader)

        # Validation
        model.eval()
        val_loss = 0.0

        with torch.no_grad():
            for batch in tqdm(val_loader, desc=f"Epoch {epoch+1} [Val]"):
                batch = batch.to(device)
                pred = model(batch)
                loss = cosine_similarity_loss(pred, batch.y)
                val_loss += loss.item()

        val_loss /= len(val_loader)

        # Scheduler step
        scheduler.step()

        # Logging
        wandb.log({
            'epoch': epoch,
            'train_loss': train_loss,
            'val_loss': val_loss,
            'learning_rate': optimizer.param_groups[0]['lr']
        })

        print(f"Epoch {epoch+1}/{config['training']['num_epochs']}: "
              f"Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}")

        # Save best model
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
            }, "models/qcgn2oei_minimal_best.pth")
            print(f"‚úÖ Best model saved (Val Loss: {val_loss:.4f})")

    print(f"Training complete. Best Val Loss: {best_val_loss:.4f}")

if __name__ == "__main__":
    train_qcgn2oei_minimal()
```

### 2.2 Ë®≠ÂÆö„Éï„Ç°„Ç§„É´ÔºàÊúÄÂ∞èÊßãÊàêÁâàÔºâ

```yaml
# config/training_minimal.yml

model:
  node_dim: 16      # Minimal (QC-GN2oMS2-inspired)
  edge_dim: 3       # Minimal (BDE + bond order + in ring)
  hidden_dim: 256
  num_layers: 10
  num_heads: 8
  output_dim: 1000
  dropout: 0.1

training:
  num_epochs: 300
  batch_size: 32
  learning_rate: 0.001
  weight_decay: 1e-5
  early_stopping_patience: 50

data:
  bde_cache: "data/processed/bde_cache.h5"
  train_data: "data/processed/nist17_train.pt"
  val_data: "data/processed/nist17_val.pt"
  test_data: "data/processed/nist17_test.pt"
```

### 2.3 Â≠¶ÁøíÊôÇÈñìË¶ãÁ©ç„ÇÇ„ÇäÔºàÈ´òÈÄüÂåñÔºâ

**„Éë„É©„É°„Éº„ÇøÊï∞„ÅÆÊØîËºÉ**:

| È†ÖÁõÆ | v4.1 (128/64) | v4.2 (16/3) | ÂâäÊ∏õÁéá |
|------|--------------|------------|--------|
| Node encoder | 128√ó256 = 32,768 | 16√ó256 = 4,096 | **-87.5%** |
| Edge encoder | 64√ó256 = 16,384 | 3√ó256 = 768 | **-95.3%** |
| EncoderÂêàË®à | 49,152 | 4,864 | **-90.1%** |

**1„Ç®„Éù„ÉÉ„ÇØ„ÅÆÊôÇÈñìÔºàÊé®ÂÆöÔºâ**:
```
224,000 samples (train) √∑ 32 batch_size = 7,000 iterations
7,000 iterations √ó 0.7 sec/iter = 4,900 sec = 1.36 hours
Ôºàv4.1: 1.56ÊôÇÈñì ‚Üí v4.2: 1.36ÊôÇÈñì„ÄÅÁ¥Ñ13%È´òÈÄüÂåñÔºâ
```

**ÂêàË®àÂ≠¶ÁøíÊôÇÈñìÔºàÊé®ÂÆöÔºâ**:
```
300 epochs √ó 1.36 hours = 408 hours
‚Üí early stopping„ÅßÁ¥Ñ40ÊôÇÈñìÔºà30„Ç®„Éù„ÉÉ„ÇØÁ®ãÂ∫¶„ÅßÂèéÊùüÊÉ≥ÂÆöÔºâ
Ôºàv4.1: 48ÊôÇÈñì ‚Üí v4.2: 40ÊôÇÈñì„ÄÅÁ¥Ñ17%È´òÈÄüÂåñÔºâ
```

---

## Phase 3: Ë©ï‰æ°„Å®ÂèçÂæ©ÊîπÂñÑÂà§Êñ≠

### 3.1 Ë©ï‰æ°„É°„Éà„É™„ÇØ„Çπ

```python
# scripts/evaluate_minimal.py
"""
Comprehensive evaluation for minimal configuration model
"""

import torch
import numpy as np
from torch_geometric.loader import DataLoader
from src.models.qcgn2oei_minimal import QCGN2oEI_Minimal
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

def cosine_similarity_metric(pred, target):
    """Calculate cosine similarity"""
    pred_norm = pred / (np.linalg.norm(pred, axis=1, keepdims=True) + 1e-8)
    target_norm = target / (np.linalg.norm(target, axis=1, keepdims=True) + 1e-8)
    return (pred_norm * target_norm).sum(axis=1).mean()

def top_k_recall(pred, target, k=10):
    """Top-K Recall"""
    recalls = []
    for p, t in zip(pred, target):
        true_top_k = set(np.argsort(t)[-k:])
        pred_top_k = set(np.argsort(p)[-k:])
        recall = len(true_top_k & pred_top_k) / k
        recalls.append(recall)
    return np.mean(recalls)

def evaluate_model(
    model_path: str = "models/qcgn2oei_minimal_best.pth",
    test_data_path: str = "data/processed/nist17_test.pt"
):
    """Comprehensive model evaluation"""

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Load model
    checkpoint = torch.load(model_path)
    model = QCGN2oEI_Minimal(
        node_dim=16,
        edge_dim=3,
        hidden_dim=256,
        num_layers=10,
        num_heads=8,
        output_dim=1000,
        dropout=0.1
    )
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()

    # Load test data
    test_data = torch.load(test_data_path)
    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

    # Inference
    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(device)
            pred = model(batch)
            all_predictions.append(pred.cpu().numpy())
            all_targets.append(batch.y.cpu().numpy())

    predictions = np.concatenate(all_predictions, axis=0)
    targets = np.concatenate(all_targets, axis=0)

    # Metrics
    cosine_sim = cosine_similarity_metric(predictions, targets)
    top5_recall = top_k_recall(predictions, targets, k=5)
    top10_recall = top_k_recall(predictions, targets, k=10)
    top20_recall = top_k_recall(predictions, targets, k=20)

    mse = mean_squared_error(targets.flatten(), predictions.flatten())
    rmse = np.sqrt(mse)

    print("=" * 60)
    print("QC-GN2oEI Minimal Configuration Evaluation")
    print("=" * 60)
    print(f"Node features: 16 dims")
    print(f"Edge features: 3 dims")
    print("-" * 60)
    print(f"Cosine Similarity: {cosine_sim:.4f}")
    print(f"Top-5 Recall:      {top5_recall:.4f}")
    print(f"Top-10 Recall:     {top10_recall:.4f}")
    print(f"Top-20 Recall:     {top20_recall:.4f}")
    print(f"MSE:               {mse:.6f}")
    print(f"RMSE:              {rmse:.6f}")
    print("=" * 60)

    # Decision logic
    print("\n" + "=" * 60)
    print("Performance Assessment")
    print("=" * 60)

    if cosine_sim >= 0.85:
        print("‚úÖ EXCELLENT: Cosine Similarity >= 0.85")
        print("   Recommendation: Adopt v4.2 minimal configuration!")
        print("   No feature expansion needed.")
    elif cosine_sim >= 0.80:
        print("‚ö†Ô∏è  GOOD: Cosine Similarity 0.80-0.85")
        print("   Recommendation: Consider minor feature additions")
        print("   Proceed to Phase 4 for targeted feature expansion")
    else:
        print("‚ùå INSUFFICIENT: Cosine Similarity < 0.80")
        print("   Recommendation: Feature expansion required")
        print("   Proceed to Phase 4 for systematic feature addition")

    return {
        'cosine_similarity': cosine_sim,
        'top5_recall': top5_recall,
        'top10_recall': top10_recall,
        'top20_recall': top20_recall,
        'mse': mse,
        'rmse': rmse
    }

if __name__ == "__main__":
    results = evaluate_model()
```

### 3.2 Âà§ÂÆöÂü∫Ê∫ñ„Å®„Ç¢„ÇØ„Ç∑„Éß„É≥„Éó„É©„É≥

| Cosine Similarity | Âà§ÂÆö | „Ç¢„ÇØ„Ç∑„Éß„É≥ |
|------------------|------|-----------|
| **‚â• 0.85** | ‚úÖ ÂÑ™ÁßÄ | **v4.2Êé°Áî®ÂÆå‰∫ÜÔºÅ** ÁâπÂæ¥ÈáèÊã°Âºµ‰∏çË¶Å |
| **0.80 - 0.85** | ‚ö†Ô∏è ËâØÂ•Ω | ËªΩÂæÆ„Å™ÊîπÂñÑÊ§úË®é ‚Üí Phase 4„Å∏ |
| **0.75 - 0.80** | ‚ö†Ô∏è Ë¶ÅÊîπÂñÑ | ÁâπÂæ¥ÈáèËøΩÂä†ÂøÖÈ†à ‚Üí Phase 4„Å∏ |
| **< 0.75** | ‚ùå ‰∏çÂçÅÂàÜ | ‰∏≠ÈñìÊßãÊàê(64/32)Ê§úË®é ‚Üí Phase 4„Å∏ |

---

## Phase 4: ÁâπÂæ¥ÈáèÊã°ÂºµÔºàÊù°‰ª∂‰ªò„ÅçÔºâ

### 4.1 ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ÂàÜÊûê

**Phase 3„ÅßCosine Sim < 0.85„ÅÆÂ†¥Âêà„ÅÆ„ÅøÂÆüÊñΩ**

```python
# scripts/analyze_feature_importance.py
"""
Analyze which features should be added next
"""

import torch
from src.models.qcgn2oei_minimal import QCGN2oEI_Minimal
import numpy as np

def analyze_attention_weights(
    model_path: str = "models/qcgn2oei_minimal_best.pth"
):
    """
    Analyze GATv2 attention weights to understand feature importance
    """

    # Load model
    model = QCGN2oEI_Minimal(...)
    checkpoint = torch.load(model_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    # Hook to capture attention weights
    attention_weights = []

    def hook_fn(module, input, output):
        # GATv2Conv returns (output, attention_weights)
        if isinstance(output, tuple):
            attention_weights.append(output[1].detach().cpu().numpy())

    # Register hooks
    for layer in model.gat_layers:
        layer.register_forward_hook(hook_fn)

    # Run inference on validation set
    # ... (collect attention weights)

    # Analyze patterns
    print("Attention Weight Analysis")
    print("=" * 60)
    # TODO: Implement analysis

    return attention_weights

def propose_feature_additions(cosine_sim: float):
    """
    Propose which features to add based on performance
    """

    print("\n" + "=" * 60)
    print("Feature Addition Recommendations")
    print("=" * 60)

    if cosine_sim >= 0.80 and cosine_sim < 0.85:
        print("Performance: GOOD (0.80-0.85)")
        print("\nRecommended additions (Priority 1):")
        print("  1. Formal charge (3 dims) - for ionic fragments")
        print("  2. Degree (6 dims) - for branching patterns")
        print("Total: +9 dims ‚Üí 16+9 = 25 node dims")

    elif cosine_sim >= 0.75 and cosine_sim < 0.80:
        print("Performance: MODERATE (0.75-0.80)")
        print("\nRecommended additions (Priority 1+2):")
        print("  Priority 1:")
        print("    - Formal charge (3 dims)")
        print("    - Degree (6 dims)")
        print("  Priority 2:")
        print("    - Hydrogen count (5 dims)")
        print("    - Conjugated bonds (1 edge dim)")
        print("Total: +14 node dims, +1 edge dim")
        print("  ‚Üí 16+14 = 30 node dims, 3+1 = 4 edge dims")

    else:  # < 0.75
        print("Performance: INSUFFICIENT (<0.75)")
        print("\nRecommended: Move to intermediate configuration")
        print("  Node: 64 dims (41 used + 23 reserved)")
        print("  Edge: 32 dims (12 used + 20 reserved)")
        print("  See v4.3 specification for details")

if __name__ == "__main__":
    # Run after Phase 3 evaluation
    results = evaluate_model()
    cosine_sim = results['cosine_similarity']

    analyze_attention_weights()
    propose_feature_additions(cosine_sim)
```

### 4.2 ÊÆµÈöéÁöÑÊã°Âºµ„Éï„É≠„Éº„ÉÅ„É£„Éº„Éà

```
Phase 3Ë©ï‰æ°ÁµêÊûú
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Cosine Similarity = ?                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚Üì
     ‚îú‚îÄ ‚â• 0.85 ‚Üí ‚úÖ ÂÆå‰∫ÜÔºÅv4.2Êé°Áî®
     ‚îÇ
     ‚îú‚îÄ 0.80-0.85 ‚Üí v4.3 (ËªΩÂæÆÊã°Âºµ)
     ‚îÇ                ‚îú‚îÄ „Éé„Éº„Éâ: 16 ‚Üí 25 (+9)
     ‚îÇ                ‚îî‚îÄ ÂÜçË©ï‰æ° ‚Üí ÂÆå‰∫Ü or „Åï„Çâ„Å´Êã°Âºµ
     ‚îÇ
     ‚îú‚îÄ 0.75-0.80 ‚Üí v4.3 (‰∏≠Â∫¶Êã°Âºµ)
     ‚îÇ                ‚îú‚îÄ „Éé„Éº„Éâ: 16 ‚Üí 30 (+14)
     ‚îÇ                ‚îú‚îÄ „Ç®„ÉÉ„Ç∏: 3 ‚Üí 4 (+1)
     ‚îÇ                ‚îî‚îÄ ÂÜçË©ï‰æ° ‚Üí ÂÆå‰∫Ü or „Åï„Çâ„Å´Êã°Âºµ
     ‚îÇ
     ‚îî‚îÄ < 0.75 ‚Üí v4.3 (‰∏≠ÈñìÊßãÊàê)
                    ‚îú‚îÄ „Éé„Éº„Éâ: 16 ‚Üí 64 (+48)
                    ‚îú‚îÄ „Ç®„ÉÉ„Ç∏: 3 ‚Üí 32 (+29)
                    ‚îî‚îÄ ÂÜçË©ï‰æ°
```

---

## Phase 5: Êé®Ë´ñ„Éó„É≠„Çª„ÇπÔºà„É¢„Éá„É´ÈÅãÁî®Ôºâ

### Ê¶ÇË¶Å

Â≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„Çí‰ΩøÁî®„Åó„Å¶„ÄÅÊñ∞Ë¶èÂåñÂêàÁâ©„ÅÆEI-MS„Çπ„Éö„ÇØ„Éà„É´„Çí‰∫àÊ∏¨„Åô„Çã„ÄÇ

### 5.1 Âçò‰∏ÄÂàÜÂ≠ê„ÅÆ‰∫àÊ∏¨

```python
# scripts/predict_single.py
"""
Predict EI-MS spectrum for a single molecule
"""

import torch
import numpy as np
from rdkit import Chem
from rdkit.Chem import AllChem
import matplotlib.pyplot as plt

from src.models.qcgn2oei_minimal import QCGN2oEI_Minimal
from src.data.bde_calculator import BDECalculator
from src.data.graph_generator import GraphGeneratorMinimal
from src.data.filters import SUPPORTED_ELEMENTS

def predict_spectrum(
    smiles: str,
    model_path: str = "models/qcgn2oei_minimal_best.pth",
    bde_model_path: str = "models/bondnet_bde_db2_best.pth",
    device: str = "cuda"
):
    """
    Predict EI-MS spectrum for a single molecule

    Args:
        smiles: SMILES string of the molecule
        model_path: Path to trained QC-GN2oEI model
        bde_model_path: Path to trained BonDNet model
        device: Device to use for inference

    Returns:
        spectrum: Predicted intensity array [1000] for m/z 50-1000
    """

    # Step 1: Validate SMILES
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        raise ValueError(f"Invalid SMILES: {smiles}")

    # Step 2: Check supported elements
    for atom in mol.GetAtoms():
        if atom.GetSymbol() not in SUPPORTED_ELEMENTS:
            raise ValueError(
                f"Unsupported element: {atom.GetSymbol()}. "
                f"Supported elements: {', '.join(sorted(SUPPORTED_ELEMENTS))}"
            )

    # Step 3: Check molecular weight
    from rdkit.Chem import Descriptors
    mw = Descriptors.MolWt(mol)
    if mw > 1000.0:
        print(f"Warning: MW={mw:.1f} > 1000 Da. Prediction may be less accurate.")

    print(f"Predicting spectrum for: {smiles}")
    print(f"  Molecular weight: {mw:.2f} Da")
    print(f"  Formula: {Chem.rdMolDescriptors.CalcMolFormula(mol)}")

    # Step 4: Calculate BDE
    print("\nStep 1: Calculating BDE...")
    bde_calc = BDECalculator(model_path=bde_model_path, device=device)
    bde_dict = bde_calc.calculate_bde(smiles)
    print(f"  Calculated BDE for {len(bde_dict)} bonds")

    # Step 5: Generate graph
    print("\nStep 2: Generating molecular graph...")
    # For single prediction, we don't have a spectrum target, so use dummy
    dummy_spectrum = np.zeros(1000)

    # Create a temporary BDE cache in memory
    import h5py
    import tempfile
    with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as tmp:
        tmp_path = tmp.name

    with h5py.File(tmp_path, 'w') as f:
        grp = f.create_group('0')
        grp.attrs['smiles'] = smiles
        for bond_idx, bde_value in bde_dict.items():
            grp.create_dataset(str(bond_idx), data=bde_value)

    # Generate graph
    graph_gen = GraphGeneratorMinimal(bde_cache_path=tmp_path)
    graph = graph_gen.smiles_to_graph(
        smiles=smiles,
        spectrum=dummy_spectrum,
        molecule_idx=0
    )

    if graph is None:
        raise ValueError("Failed to generate graph")

    print(f"  Graph: {graph.x.shape[0]} nodes, {graph.edge_index.shape[1]} edges")
    print(f"  Node features: {graph.x.shape[1]} dims (minimal)")
    print(f"  Edge features: {graph.edge_attr.shape[1]} dims (minimal)")

    # Step 6: Load model
    print("\nStep 3: Loading trained model...")
    device = torch.device(device if torch.cuda.is_available() else "cpu")

    model = QCGN2oEI_Minimal(
        node_dim=16,
        edge_dim=3,
        hidden_dim=256,
        num_layers=10,
        num_heads=8,
        output_dim=1000,
        dropout=0.1
    )

    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()

    print(f"  Model loaded from: {model_path}")
    print(f"  Using device: {device}")

    # Step 7: Inference
    print("\nStep 4: Predicting spectrum...")
    graph = graph.to(device)

    with torch.no_grad():
        spectrum_pred = model(
            x=graph.x,
            edge_index=graph.edge_index,
            edge_attr=graph.edge_attr,
            batch=graph.batch
        )

    spectrum = spectrum_pred.cpu().numpy().squeeze()

    print(f"  Prediction complete")
    print(f"  Spectrum shape: {spectrum.shape}")
    print(f"  Max intensity: {spectrum.max():.4f}")
    print(f"  Number of peaks (intensity > 0.01): {(spectrum > 0.01).sum()}")

    # Cleanup temp file
    import os
    os.unlink(tmp_path)

    return spectrum


def visualize_spectrum(
    spectrum: np.ndarray,
    smiles: str,
    output_path: str = "predicted_spectrum.png",
    mz_range: tuple = (50, 1000)
):
    """
    Visualize predicted spectrum

    Args:
        spectrum: Predicted intensity array [1000]
        smiles: SMILES string (for title)
        output_path: Path to save plot
        mz_range: m/z range (min, max)
    """

    mz_values = np.arange(mz_range[0], mz_range[1])

    # Pad spectrum if needed
    if len(spectrum) < len(mz_values):
        spectrum = np.pad(spectrum, (0, len(mz_values) - len(spectrum)))
    elif len(spectrum) > len(mz_values):
        spectrum = spectrum[:len(mz_values)]

    # Create plot
    fig, ax = plt.subplots(figsize=(12, 6))

    # Stem plot for spectrum
    ax.stem(mz_values, spectrum, linefmt='b-', markerfmt='bo', basefmt=" ")

    ax.set_xlabel("m/z", fontsize=12)
    ax.set_ylabel("Relative Intensity", fontsize=12)
    ax.set_title(f"Predicted EI-MS Spectrum\n{smiles}", fontsize=14)
    ax.grid(True, alpha=0.3)
    ax.set_xlim(mz_range)
    ax.set_ylim(0, spectrum.max() * 1.1)

    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"\n‚úÖ Spectrum saved to: {output_path}")

    return fig


def get_top_peaks(spectrum: np.ndarray, top_k: int = 10, mz_offset: int = 50):
    """
    Extract top-K peaks from spectrum

    Args:
        spectrum: Intensity array
        top_k: Number of top peaks to extract
        mz_offset: m/z offset (default: 50 for m/z 50-1000 range)

    Returns:
        List of (m/z, intensity) tuples
    """

    # Find top-K indices
    top_indices = np.argsort(spectrum)[-top_k:][::-1]

    # Convert to (m/z, intensity) pairs
    peaks = []
    for idx in top_indices:
        mz = idx + mz_offset
        intensity = spectrum[idx]
        if intensity > 0.001:  # Filter very small peaks
            peaks.append((mz, intensity))

    return peaks


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Predict EI-MS spectrum for a molecule")
    parser.add_argument("smiles", type=str, help="SMILES string")
    parser.add_argument("--model", type=str, default="models/qcgn2oei_minimal_best.pth",
                        help="Path to trained model")
    parser.add_argument("--bde-model", type=str, default="models/bondnet_bde_db2_best.pth",
                        help="Path to BonDNet model")
    parser.add_argument("--output", type=str, default="predicted_spectrum.png",
                        help="Output plot path")
    parser.add_argument("--device", type=str, default="cuda", help="Device (cuda/cpu)")

    args = parser.parse_args()

    # Predict
    spectrum = predict_spectrum(
        smiles=args.smiles,
        model_path=args.model,
        bde_model_path=args.bde_model,
        device=args.device
    )

    # Get top peaks
    top_peaks = get_top_peaks(spectrum, top_k=10)
    print("\n" + "=" * 60)
    print("Top 10 Predicted Peaks")
    print("=" * 60)
    for i, (mz, intensity) in enumerate(top_peaks, 1):
        print(f"{i:2d}. m/z {mz:4d}  Intensity: {intensity:.4f}")

    # Visualize
    visualize_spectrum(spectrum, args.smiles, args.output)
```

**ÂÆüË°å‰æã**:
```bash
# Example: Predict spectrum for caffeine
python scripts/predict_single.py "CN1C=NC2=C1C(=O)N(C(=O)N2C)C" \
    --model models/qcgn2oei_minimal_best.pth \
    --output caffeine_spectrum.png
```

**Âá∫Âäõ‰æã**:
```
Predicting spectrum for: CN1C=NC2=C1C(=O)N(C(=O)N2C)C
  Molecular weight: 194.19 Da
  Formula: C8H10N4O2

Step 1: Calculating BDE...
  Calculated BDE for 21 bonds

Step 2: Generating molecular graph...
  Graph: 24 nodes, 50 edges
  Node features: 16 dims (minimal)
  Edge features: 3 dims (minimal)

Step 3: Loading trained model...
  Model loaded from: models/qcgn2oei_minimal_best.pth
  Using device: cuda

Step 4: Predicting spectrum...
  Prediction complete
  Spectrum shape: (1000,)
  Max intensity: 0.9234
  Number of peaks (intensity > 0.01): 47

============================================================
Top 10 Predicted Peaks
============================================================
 1. m/z  194  Intensity: 0.9234
 2. m/z  109  Intensity: 0.7821
 3. m/z   82  Intensity: 0.5432
 4. m/z  165  Intensity: 0.4211
 5. m/z   67  Intensity: 0.3890
 6. m/z  136  Intensity: 0.3234
 7. m/z   55  Intensity: 0.2987
 8. m/z  151  Intensity: 0.2654
 9. m/z   96  Intensity: 0.2341
10. m/z  123  Intensity: 0.2104

‚úÖ Spectrum saved to: caffeine_spectrum.png
```

---

### 5.2 „Éê„ÉÉ„ÉÅ‰∫àÊ∏¨

```python
# scripts/predict_batch.py
"""
Batch prediction for multiple molecules
"""

import torch
import pandas as pd
from torch_geometric.loader import DataLoader
from tqdm import tqdm
import h5py

from src.models.qcgn2oei_minimal import QCGN2oEI_Minimal
from src.data.bde_calculator import BDECalculator
from src.data.graph_generator import GraphGeneratorMinimal

def predict_batch(
    smiles_list: list,
    model_path: str = "models/qcgn2oei_minimal_best.pth",
    bde_model_path: str = "models/bondnet_bde_db2_best.pth",
    output_csv: str = "predictions.csv",
    batch_size: int = 32,
    device: str = "cuda"
):
    """
    Batch prediction for multiple molecules

    Args:
        smiles_list: List of SMILES strings
        model_path: Path to trained model
        bde_model_path: Path to BonDNet model
        output_csv: Output CSV file path
        batch_size: Batch size for inference
        device: Device for inference

    Returns:
        DataFrame with predictions
    """

    print(f"Batch prediction for {len(smiles_list)} molecules")

    # Step 1: Calculate BDE for all molecules
    print("\nStep 1: Calculating BDE...")
    bde_calc = BDECalculator(model_path=bde_model_path, device=device)

    bde_cache_path = "temp_bde_cache.h5"
    with h5py.File(bde_cache_path, 'w') as f:
        for i, smiles in enumerate(tqdm(smiles_list, desc="BDE calculation")):
            bde_dict = bde_calc.calculate_bde(smiles)

            grp = f.create_group(str(i))
            grp.attrs['smiles'] = smiles
            for bond_idx, bde_value in bde_dict.items():
                grp.create_dataset(str(bond_idx), data=bde_value)

    # Step 2: Generate graphs
    print("\nStep 2: Generating graphs...")
    graph_gen = GraphGeneratorMinimal(bde_cache_path)

    graphs = []
    valid_indices = []
    for i, smiles in enumerate(tqdm(smiles_list, desc="Graph generation")):
        import numpy as np
        dummy_spectrum = np.zeros(1000)

        graph = graph_gen.smiles_to_graph(
            smiles=smiles,
            spectrum=dummy_spectrum,
            molecule_idx=i
        )

        if graph is not None:
            graphs.append(graph)
            valid_indices.append(i)

    print(f"Generated {len(graphs)} valid graphs")

    # Step 3: Load model
    print("\nStep 3: Loading model...")
    device = torch.device(device if torch.cuda.is_available() else "cpu")

    model = QCGN2oEI_Minimal(
        node_dim=16,
        edge_dim=3,
        hidden_dim=256,
        num_layers=10,
        num_heads=8,
        output_dim=1000,
        dropout=0.1
    )

    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()

    # Step 4: Batch inference
    print("\nStep 4: Predicting spectra...")
    loader = DataLoader(graphs, batch_size=batch_size, shuffle=False)

    all_predictions = []
    with torch.no_grad():
        for batch in tqdm(loader, desc="Inference"):
            batch = batch.to(device)
            pred = model(batch)
            all_predictions.append(pred.cpu().numpy())

    predictions = np.concatenate(all_predictions, axis=0)

    # Step 5: Create results DataFrame
    print("\nStep 5: Creating results...")
    results = []
    for i, pred in zip(valid_indices, predictions):
        smiles = smiles_list[i]
        top_peaks = get_top_peaks(pred, top_k=10)

        results.append({
            'smiles': smiles,
            'top_mz': [p[0] for p in top_peaks],
            'top_intensity': [p[1] for p in top_peaks],
            'base_peak_mz': top_peaks[0][0] if top_peaks else None,
            'base_peak_intensity': top_peaks[0][1] if top_peaks else None,
            'num_peaks': (pred > 0.01).sum()
        })

    df = pd.DataFrame(results)
    df.to_csv(output_csv, index=False)

    print(f"\n‚úÖ Predictions saved to: {output_csv}")

    # Cleanup
    import os
    os.unlink(bde_cache_path)

    return df


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Batch EI-MS spectrum prediction")
    parser.add_argument("input", type=str, help="Input CSV file with 'smiles' column")
    parser.add_argument("--output", type=str, default="predictions.csv",
                        help="Output CSV file")
    parser.add_argument("--model", type=str, default="models/qcgn2oei_minimal_best.pth")
    parser.add_argument("--bde-model", type=str, default="models/bondnet_bde_db2_best.pth")
    parser.add_argument("--batch-size", type=int, default=32)
    parser.add_argument("--device", type=str, default="cuda")

    args = parser.parse_args()

    # Load SMILES
    df = pd.read_csv(args.input)
    smiles_list = df['smiles'].tolist()

    # Predict
    results = predict_batch(
        smiles_list=smiles_list,
        model_path=args.model,
        bde_model_path=args.bde_model,
        output_csv=args.output,
        batch_size=args.batch_size,
        device=args.device
    )

    print(f"\nProcessed {len(results)} molecules")
```

**ÂÆüË°å‰æã**:
```bash
# Batch prediction from CSV
python scripts/predict_batch.py compounds.csv \
    --output predictions.csv \
    --batch-size 64
```

---

### 5.3 REST APIÔºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ

```python
# api/main.py
"""
FastAPI server for EI-MS prediction
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import torch
import numpy as np

from src.models.qcgn2oei_minimal import QCGN2oEI_Minimal
from scripts.predict_single import predict_spectrum, get_top_peaks

app = FastAPI(title="QC-GN2oEI Prediction API")

# Global model (loaded once at startup)
MODEL = None
DEVICE = None


class PredictionRequest(BaseModel):
    smiles: str
    top_k: int = 10


class PredictionResponse(BaseModel):
    smiles: str
    spectrum: list
    top_peaks: list
    base_peak_mz: int
    base_peak_intensity: float


@app.on_event("startup")
async def load_model():
    """Load model at startup"""
    global MODEL, DEVICE

    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    MODEL = QCGN2oEI_Minimal(
        node_dim=16,
        edge_dim=3,
        hidden_dim=256,
        num_layers=10,
        num_heads=8,
        output_dim=1000,
        dropout=0.1
    )

    checkpoint = torch.load("models/qcgn2oei_minimal_best.pth", map_location=DEVICE)
    MODEL.load_state_dict(checkpoint['model_state_dict'])
    MODEL.to(DEVICE)
    MODEL.eval()

    print(f"Model loaded on {DEVICE}")


@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    """Predict EI-MS spectrum for a molecule"""

    try:
        # Predict spectrum
        spectrum = predict_spectrum(
            smiles=request.smiles,
            model_path="models/qcgn2oei_minimal_best.pth",
            bde_model_path="models/bondnet_bde_db2_best.pth",
            device=str(DEVICE)
        )

        # Get top peaks
        top_peaks = get_top_peaks(spectrum, top_k=request.top_k)

        return PredictionResponse(
            smiles=request.smiles,
            spectrum=spectrum.tolist(),
            top_peaks=[[int(mz), float(intensity)] for mz, intensity in top_peaks],
            base_peak_mz=int(top_peaks[0][0]),
            base_peak_intensity=float(top_peaks[0][1])
        )

    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@app.get("/")
async def root():
    """API information"""
    return {
        "name": "QC-GN2oEI Prediction API",
        "version": "4.2",
        "model": "Minimal Configuration (16 node, 3 edge dims)",
        "endpoints": ["/predict", "/health"]
    }


@app.get("/health")
async def health():
    """Health check"""
    return {
        "status": "healthy",
        "model_loaded": MODEL is not None,
        "device": str(DEVICE)
    }
```

**requirements_api.txt**:
```
fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.5.0
```

**Ëµ∑ÂãïÊñπÊ≥ï**:
```bash
# Install dependencies
pip install -r requirements_api.txt

# Start server
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload

# API available at: http://localhost:8000
# Docs at: http://localhost:8000/docs
```

**API„ÅÆ‰ΩøÁî®‰æã**:
```bash
# cURL„Åß„É™„ÇØ„Ç®„Çπ„Éà
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"smiles": "CCO", "top_k": 5}'
```

**„É¨„Çπ„Éù„É≥„Çπ‰æã**:
```json
{
  "smiles": "CCO",
  "spectrum": [0.0, 0.0, ..., 0.9234, ...],
  "top_peaks": [
    [46, 0.9234],
    [31, 0.7821],
    [45, 0.5432],
    [27, 0.3211],
    [29, 0.2987]
  ],
  "base_peak_mz": 46,
  "base_peak_intensity": 0.9234
}
```

---

### 5.4 ÊÄßËÉΩÊúÄÈÅ©Âåñ

#### GPUÊé®Ë´ñ„ÅÆÊúÄÈÅ©Âåñ

```python
# Ê∑∑ÂêàÁ≤æÂ∫¶Êé®Ë´ñ
model.half()  # FP16
graph = graph.half()

with torch.cuda.amp.autocast():
    pred = model(graph)
```

#### „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„ÅÆÊúÄÈÅ©Âåñ

| GPU | Êé®Â•®„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫ | „É°„É¢„É™‰ΩøÁî®Èáè |
|-----|----------------|-------------|
| RTX 5070 Ti (16GB) | 64-128 | Á¥Ñ4-8GB |
| RTX 4090 (24GB) | 128-256 | Á¥Ñ8-12GB |
| RTX 3090 (24GB) | 128-256 | Á¥Ñ8-12GB |

#### Êé®Ë´ñÈÄüÂ∫¶„Éô„É≥„ÉÅ„Éû„Éº„ÇØ

**RTX 5070 Ti**:
- Âçò‰∏ÄÂàÜÂ≠ê: Á¥Ñ50msÔºàBDEË®àÁÆó25ms + Êé®Ë´ñ25msÔºâ
- „Éê„ÉÉ„ÉÅ64: Á¥Ñ15ms/ÂàÜÂ≠ê
- „Éê„ÉÉ„ÉÅ128: Á¥Ñ12ms/ÂàÜÂ≠ê

**„Çπ„É´„Éº„Éó„ÉÉ„Éà**:
- Âçò‰∏ÄÂàÜÂ≠ê: 20 molecules/sec
- „Éê„ÉÉ„ÉÅ64: 4,267 molecules/sec
- „Éê„ÉÉ„ÉÅ128: 8,000 molecules/sec

---

### 5.5 Êé®Ë´ñÁµêÊûú„ÅÆÊ§úË®º

```python
# scripts/validate_prediction.py
"""
Validate prediction against known spectrum (if available)
"""

import numpy as np
from scipy.stats import pearsonr

def validate_prediction(
    predicted_spectrum: np.ndarray,
    true_spectrum: np.ndarray
):
    """
    Validate prediction against true spectrum

    Returns:
        dict with validation metrics
    """

    # Cosine similarity
    pred_norm = predicted_spectrum / (np.linalg.norm(predicted_spectrum) + 1e-8)
    true_norm = true_spectrum / (np.linalg.norm(true_spectrum) + 1e-8)
    cosine_sim = np.dot(pred_norm, true_norm)

    # Pearson correlation
    pearson_r, _ = pearsonr(predicted_spectrum, true_spectrum)

    # MSE
    mse = np.mean((predicted_spectrum - true_spectrum) ** 2)

    # Top-K recall
    top_k_recalls = {}
    for k in [5, 10, 20]:
        true_top_k = set(np.argsort(true_spectrum)[-k:])
        pred_top_k = set(np.argsort(predicted_spectrum)[-k:])
        recall = len(true_top_k & pred_top_k) / k
        top_k_recalls[f'top_{k}_recall'] = recall

    return {
        'cosine_similarity': cosine_sim,
        'pearson_correlation': pearson_r,
        'mse': mse,
        'rmse': np.sqrt(mse),
        **top_k_recalls
    }
```

---

## Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ë©≥Á¥∞

### config.ymlÔºà„É°„Ç§„É≥Ë®≠ÂÆö„ÄÅv4.2ÊúÄÂ∞èÊßãÊàêÁâàÔºâ

```yaml
# config.yml - Main Configuration (v4.2 Minimal)

project:
  name: "QC-GN2oEI"
  version: "2.2-minimal"
  description: "Minimal configuration approach with iterative refinement"
  design_philosophy: "Start simple, iterate based on evidence"

# BDE Configuration
bde:
  backend: "bondnet"
  bondnet:
    model_type: "bde-db2"
    model_path: "models/bondnet_bde_db2_best.pth"
    dataset_path: "data/external/bde-db2"
    device: "cuda"
    batch_size: 256

# Data paths
data:
  nist17_path: "data/external/nist17/mainlib"
  bde_cache: "data/processed/bde_cache.h5"
  train_data: "data/processed/nist17_train.pt"
  val_data: "data/processed/nist17_val.pt"
  test_data: "data/processed/nist17_test.pt"

  # Data filtering
  filtering:
    supported_elements: ['C', 'H', 'O', 'N', 'F', 'S', 'P', 'Cl', 'Br', 'I']
    min_molecular_weight: 50.0
    max_molecular_weight: 1000.0
    validate_smiles: true

# Model architecture (MINIMAL CONFIGURATION)
model:
  type: "QCGN2oEI_Minimal"

  # Minimal feature dimensions (QC-GN2oMS2-inspired)
  node_dim: 16   # No reserved dims
  edge_dim: 3    # No reserved dims

  # GNN layers
  hidden_dim: 256
  num_layers: 10
  num_heads: 8

  # Output
  output_dim: 1000

  # Regularization
  dropout: 0.1

  # Advanced features
  use_residual: true
  use_edge_features: true
  global_pooling: "mean"

# Training
training:
  num_epochs: 300
  batch_size: 32
  learning_rate: 0.001
  weight_decay: 1e-5

  optimizer: "RAdam"
  scheduler: "CosineAnnealingLR"
  scheduler_params:
    T_max: 300
    eta_min: 1e-6

  loss: "cosine_similarity"
  early_stopping_patience: 50

  checkpoint_dir: "checkpoints"
  save_every: 10

# Evaluation & Iteration
evaluation:
  metrics:
    - "cosine_similarity"
    - "top_k_recall"
    - "mse"
    - "rmse"

  top_k_values: [5, 10, 20, 50]

  # Performance thresholds for iteration decision
  performance_thresholds:
    excellent: 0.85      # No feature expansion needed
    good: 0.80           # Minor additions considered
    moderate: 0.75       # Feature additions recommended
    insufficient: 0.0    # Significant expansion required

  # Feature expansion plan (conditional)
  feature_expansion:
    enabled: true
    analyze_attention: true
    ablation_study: true

# Hardware
hardware:
  device: "cuda"
  gpu_id: 0
  num_workers: 4
  pin_memory: true
  use_amp: true
  amp_dtype: "float16"

# Logging
logging:
  use_wandb: true
  wandb_project: "qcgn2oei-minimal"
  wandb_entity: null
  log_every: 10
  save_predictions: true

# Reproducibility
seed: 42
deterministic: true
```

---

## ÈñãÁô∫Áí∞Â¢ÉÊßãÁØâ

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

---

## „Çø„Ç§„É†„É©„Ç§„É≥

### ÂÖ®‰Ωì„Çπ„Ç±„Ç∏„É•„Éº„É´Ôºàv4.2Êõ¥Êñ∞ÁâàÔºâ

| „Éï„Çß„Éº„Ç∫ | „Çø„Çπ„ÇØ | Êé®ÂÆöÊôÇÈñì | Á¥ØÁ©çÊôÇÈñì |
|---------|--------|---------|---------|
| **Phase 0** | BDE-db2„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ | 30ÂàÜ | 30ÂàÜ |
| **Phase 0** | „Éá„Éº„ÇøÂâçÂá¶ÁêÜ | 3ÊôÇÈñì | 3.5ÊôÇÈñì |
| **Phase 0** | BonDNetÂÜçÂ≠¶Áøí | 48-72ÊôÇÈñì | 51.5-75.5ÊôÇÈñì |
| **Phase 0** | „É¢„Éá„É´Ê§úË®º | 1ÊôÇÈñì | 52.5-76.5ÊôÇÈñì |
| **Phase 1** | NISTË™≠„ÅøËæº„Åø | 30ÂàÜ | 53-77ÊôÇÈñì |
| **Phase 1** | „Éá„Éº„Çø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞ | 10ÂàÜ | 53.17-77.17ÊôÇÈñì |
| **Phase 1** | BDEË®àÁÆóÔºà280KÔºâ | 70ÂàÜ | 54.33-78.33ÊôÇÈñì |
| **Phase 1** | PyG GraphÁîüÊàêÔºà16/3Ê¨°ÂÖÉÔºâ | 60ÂàÜ | 55.33-79.33ÊôÇÈñì |
| **Phase 2** | GNNÂ≠¶ÁøíÔºàÊúÄÂ∞èÊßãÊàêÔºâ | **40ÊôÇÈñì** | **95.33-119.33ÊôÇÈñì** |
| **Phase 3** | Ë©ï‰æ°„ÉªÂà§ÂÆö | 2ÊôÇÈñì | 97.33-121.33ÊôÇÈñì |
| **Phase 4** | ÁâπÂæ¥ÈáèÊã°ÂºµÔºàÊù°‰ª∂‰ªò„ÅçÔºâ | 0-24ÊôÇÈñì | 97.33-145.33ÊôÇÈñì |
| **ÂêàË®à** | - | **97-145ÊôÇÈñì** | **4.0-6.0Êó•** |

**v4.2„Åß„ÅÆÂ§âÊõ¥**:
- GNNÂ≠¶ÁøíÊôÇÈñì: 48ÊôÇÈñì ‚Üí 40ÊôÇÈñìÔºà-17%„ÄÅÈ´òÈÄüÂåñÔºâ
- Phase 4ËøΩÂä†ÔºàÊù°‰ª∂‰ªò„ÅçÔºâ: ÊÄßËÉΩ‰∏çË∂≥ÊôÇ„ÅÆ„ÅøÂÆüÊñΩ

---

## ÂèÇËÄÉÊñáÁåÆ

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

---

## „Åæ„Å®„ÇÅ

### v4.2„ÅÆ‰∏ªË¶Å„Å™ÊîπÂñÑÁÇπ

1. **ÊúÄÂ∞èÊßãÊàê„Ç¢„Éó„É≠„Éº„ÉÅ**: QC-GN2oMS2„ÅÆÂÆüË®ºÊ∏à„ÅøË®≠Ë®à„Å´Ê∫ñÊã†
2. **„É°„É¢„É™ÂäπÁéá**: v4.1ÊØî„Åß88%ÂâäÊ∏õÔºà1.3GB ‚Üí 0.16GBÔºâ
3. **Â≠¶ÁøíÈ´òÈÄüÂåñ**: v4.1ÊØî„Åß17%È´òÈÄüÂåñÔºà48ÊôÇÈñì ‚Üí 40ÊôÇÈñìÔºâ
4. **ÂèçÂæ©ÊîπÂñÑÊà¶Áï•**: ÊÄßËÉΩË©ï‰æ° ‚Üí ÂøÖË¶Å„Å´Âøú„Åò„Å¶ÊÆµÈöéÁöÑÊã°Âºµ
5. **ÂÆüË®º‰∏ªÁæ©**: "Start simple, iterate based on evidence"

### ÊúüÂæÖ„Åï„Çå„ÇãÊàêÊûú

**„Éô„Çπ„Éà„Ç±„Éº„ÇπÔºàCosine Sim ‚â• 0.85Ôºâ**:
- ‚úÖ v4.2Êé°Áî®ÂÆå‰∫ÜÔºàÊúÄÂ∞èÊßãÊàê„ÅßÂçÅÂàÜÔºâ
- „É°„É¢„É™ÂäπÁéá„ÉªÂ≠¶ÁøíÈÄüÂ∫¶„ÅÆÂ§ßÂπÖÊîπÂñÑ
- QC-GN2oMS2„ÅÆÊàêÂäü„ÇíÂÜçÁèæ

**‰∏≠Èñì„Ç±„Éº„ÇπÔºàCosine Sim 0.80-0.85Ôºâ**:
- v4.3„ÅßËªΩÂæÆ„Å™ÁâπÂæ¥ËøΩÂä†Ôºà+9-14Ê¨°ÂÖÉÔºâ
- ÂêàÁêÜÁöÑ„Å™„Éà„É¨„Éº„Éâ„Ç™„Éï

**ÊúÄÊÇ™„Ç±„Éº„ÇπÔºàCosine Sim < 0.75Ôºâ**:
- ‰∏≠ÈñìÊßãÊàêÔºà64/32Ê¨°ÂÖÉÔºâ„Å´Êã°Âºµ
- „Åù„Çå„Åß„ÇÇv4.1„Çà„ÇäÂäπÁéáÁöÑ

---

**Document Version**: 4.2
**Last Updated**: 2025-12-02
**Status**: Ready for Implementation (Minimal Configuration with Iterative Refinement)
**Design Philosophy**: Start Simple, Iterate Based on Evidence
